* Python 기초 4: 모듈, 예외, 오류

** TODO 모듈 사용하기

코드가 점점 커지면, 코드를 하나의 파일에 담기 어려워지게 됩니다. 그럴 때는 코드를 여러 개의 파일로 나누어 놓고, 필요한 내용들을 불러와서 사용하게 되는데, '불러와서 사용할 수 있게 되어 있는 형태'를 모듈이라고 합니다.

초기에는 여러분이 직접 모듈을 만들기보다는 다른 사람들이 만들어놓은 모듈을 사용할 일이 더 많이 있을겁니다.

모듈을 사용하기 위해서는 우선 모듈을 불러들여서 메모리상에 적재해야 합니다.

모듈을 적재하려면 ~import~ 구문을 사용합니다. import된 모듈은 ~.~ 을 통해서 그 안에 포함된 함수, 변수, 클래스 등에 접근할 수 있습니다.

#+BEGIN_SRC python :results output :exports both
import os
print(os.listdir('.'))
#+END_SRC

#+RESULTS:
: ['.git', '.gitignore', '.mypy_cache', 'LICENSE.md', 'README.org', 'assets', 'beautifulsoup.org', 'excel-1.org', 'excel-2.org', 'installation.org', 'jupyter-install.org', 'kevin.org', 'language-basic-1.org', 'language-basic-2.org', 'language-basic-3.org', 'language-basic-4.org', 'obipy-resources', 'outputs', 'pandas.org', 'proficiency.org', 'python-overview.org', 'qna.org', 'refactoring.org', 'regex.org', 'testing.org']

또는 ~from ... import~ 구문을 사용하여 특정 모듈 내의 원하는 대상을 모듈 접두어 없이 곧바로 참조할 수 있습니다.

#+BEGIN_SRC python :results output :exports both
from os import listdir
print(listdir('.'))
#+END_SRC

#+RESULTS:
: ['.git', '.gitignore', '.mypy_cache', 'LICENSE.md', 'README.org', 'assets', 'beautifulsoup.org', 'excel-1.org', 'excel-2.org', 'installation.org', 'jupyter-install.org', 'kevin.org', 'language-basic-1.org', 'language-basic-2.org', 'language-basic-3.org', 'language-basic-4.org', 'obipy-resources', 'outputs', 'pandas.org', 'proficiency.org', 'python-overview.org', 'qna.org', 'refactoring.org', 'regex.org', 'testing.org']

모듈의 이름이 길거나 겹치는 등의 이유로 별칭으로 접근하도록 지정할 수 있습니다.

#+BEGIN_SRC ipython :results raw :exports both :ipyfile outputs/basic-4-module-examp-1.png
from matplotlib import pyplot as plt

plt.plot([1, 2, 3, 4, 5])
plt.show()
#+END_SRC

#+RESULTS:
[[file:outputs/basic-4-module-examp-1.png]]


Anaconda가 다양한 패키지들을 미리 포함하고 있기는 하지만, 필요한 패키지가 모두 포함되어있지는 않습니다. 때에 따라서 외부 패키지를 설치해야 합니다.

[[http://arrow.readthedocs.io/en/latest/][arrow]]라는 패키지는 Python에서 날짜를 손쉽게 다룰 수 있게 도와줍니다. 이 패키지는 Anaconda에 기본적으로 포함되어 있지 않습니다. 이 패키지를 설치해봅시다. Anaconda Prompt를 실행하고 아래 명령을 입력해줍니다.

#+BEGIN_SRC sh
conda install arrow
#+END_SRC

이제 ~arrow~ 패키지를 사용할 수 있습니다.

#+BEGIN_SRC python :exports both :results output
import arrow
print(arrow.get('2018-01-03 09:10:00+09:00'))
#+END_SRC

#+RESULTS:
: 2018-01-03T09:10:00+09:00

위에서는 ~conda~ 를 사용하여 패키지를 설치했습니다. ~conda~ 패키지 관리자는 Anaconda에서 관리합니다. 그런데 간혹 Anaconda 저장소에 올라가 있지 않은 패키지가 있습니다. 대표적으로 한글 형태소 분석기 모음인 KoNLPy 패키지가 그렇습니다. 이런 경우에는 ~pip~ 패키지 관리자를 사용하여 설치할 수 있습니다. ~pip~ 패키지 관리자는 Python에 가장 기본적으로 포함되어 있는 도구입니다.

#+BEGIN_SRC sh
pip install jpype1
pip install konlpy
#+END_SRC

(KoNLPy를 사용하기 위해서는 Java Runtime이 설치되어 있어야 합니다.)


** TODO 예외 처리하기

이번에는 예외 처리에 대해 알아보겠습니다.

프로그램을 의도대로 작성하다보면, 의도와 다르게 동작하는 경우를 고려해야 할 때가 있습니다. 이를테면 하위 디렉토리에 파일을 생성하려고 했는데, 그 디렉토리가 아직 존재하지 않는 경우, 아니면 웹에서 정보를 가져오도록 했는데 인터넷 연결이 끊어진 경우 등이 있겠죠. 이런 경우에, 프로그램이 그 의도하지 않은 상황, 즉 예외 상황에 대해서 어떻게 동작해야 하는지 일러주어야 합니다.

#+BEGIN_SRC python :exports both :results output
  a_list = [1, 2, 3, 4, 5]
  a_list[5]                       # IndexError가 발생. 참조는 0부터 시작하기 때문에, '5'를 참조하기 위해서는 4를 지정해야 함.
#+END_SRC

#+RESULTS:
: Traceback (most recent call last):
:  File "<stdin>", line 1, in <module>
: IndexError: list index out of range

#+BEGIN_SRC python :exports both :results output
  a_dict = {'Tom': 32, 'Chris': 20}
  a_dict['Mary']                  # KeyError가 발생. a_dict에 Mary는 존재하지 않음.
#+END_SRC

#+RESULTS:
: Traceback (most recent call last):
:  File "<stdin>", line 1, in <module>
: KeyError: 'Mary'

아마도 여러분이 직접 예외 상황을 만들 일보다는 기본 라이브러리나 외부 라이브러리에서 발생하는 예외 상황을 처리해야 할 경우가 많을 것입니다. 발생할 예외를 처리할 구문을 지정하기 위해서는 ~try... except...~ 구문을 사용합니다.




 - 예외 처리하기: try ... except
 - 예외도 클래스다. 예외 클래스 import하기


** TODO 오류 대응하기

 - 오류에 익숙해지기
 - 오류 메세지 읽기
 - 오류 메세지 검색하기


#+BEGIN_SRC python :exports both :results output
  import requests
  requests.get('http://domainnotexists.com')
#+END_SRC


** 연습문제

NLP 엔진을 사용하여 문장을 형태소 단위로 구분하고, 각 요소에 품사를 식별하여 붙여보겠습니다.

#+BEGIN_SRC ipython :session :exports both :results output
from konlpy.tag import Twitter
tw = Twitter()
result = tw.pos('존경하고 사랑하는 국민 여러분, 감사합니다. 국민 여러분의 위대한 선택에 머리숙여 깊이 감사드립니다.')
print(result)
#+END_SRC

#+RESULTS:
: [('존경하고', 'Verb'), ('사랑하는', 'Verb'), ('국민', 'Noun'), ('여러분', 'Noun'), (',', 'Punctuation'), ('감사합', 'Verb'), ('니다', 'Eomi'), ('.', 'Punctuation'), ('국민', 'Noun'), ('여러분', 'Noun'), ('의', 'Josa'), ('위대한', 'Adjective'), ('선택', 'Noun'), ('에', 'Josa'), ('머리', 'Noun'), ('숙여', 'Verb'), ('깊이', 'Noun'), ('감사', 'Noun'), ('드립니', 'Verb'), ('다', 'Eomi'), ('.', 'Punctuation')]


위의 NLP 엔진 사용법을 활용하여 의미망을 다시 그려봅시다.

#+BEGIN_SRC ipython :results output :exports both
  import networkx as nx
  import matplotlib.pyplot as plt
  from konlpy.tag import Twitter

  def read_file(path):
      with open(path) as fin:
          return fin.read()

  def construct_wordnet(text):
      tw = Twitter()
      lines = text.split('\n')      # 줄 단위로 자른다

      word_edges = {}

      for line in lines:
          _line = line.strip()
          if not _line:             # 빈줄이면 건너뛴다
              continue
          statements = _line.split('.') # 문장 단위로 자른다
          for statement in statements: # 빈 문장이면 건너뛴다
              if not statement:
                  continue
              words = tw.pos(statement)
              cleansed_words = [w[0] for w in words if w[1] not in ('Punctuation', 'Josa', 'Eomi') and len(w[0]) > 1]
              num_words = len(cleansed_words)
              for index_i in range(num_words): # 한 문장에 등장한 단어들을 서로 연결한다
                  word_i = cleansed_words[index_i]
                  for index_j in range(index_i+1, num_words):
                      word_j = cleansed_words[index_j]
                      word_to_word = (word_i, word_j)
                      word_to_word = tuple(sorted(word_to_word))
                      word_edges[word_to_word] = word_edges.setdefault(word_to_word, 0) + 1
      return word_edges

  def remove_low_frequency(word_edges, cutoff=2):
      # 등장 빈도가 1회인 edge는 제거한다
      keys = list(word_edges.keys())
      for key in keys:
          if word_edges[key] < cutoff:
              del word_edges[key]
      return

  def draw_graph(word_edges):
      G = nx.Graph()
      for (word_1, word_2), freq in word_edges.items():
          G.add_edge(word_1, word_2, weight=freq)

      pos = nx.kamada_kawai_layout(G)
      plt.figure(figsize=(12, 12))    # 결과 이미지 크기를 크게 지정 (12inch * 12inch)
      widths = [G[node1][node2]['weight'] for node1, node2 in G.edges()]
      nx.draw_networkx_edges(G, pos, width=widths, alpha=0.1)
      nx.draw_networkx_labels(G, pos, font_family='Noto Sans CJK KR') # 각자 시스템에 따라 적절한 폰트 이름으로 변경
      return
#+END_SRC

#+BEGIN_SRC ipython :results raw :exports both :ipyfile outputs/moon_speech_nlp.png
  text = read_file('assets/moon_speech.txt')
  wordnet = construct_wordnet(text)
  remove_low_frequency(wordnet)
  draw_graph(wordnet)
  plt.show()
#+END_SRC

#+RESULTS:
[[file:outputs/moon_speech_nlp.png]]


#+BEGIN_SRC ipython :results raw :exports both :ipyfile outputs/park_speech_nlp.png
  text = read_file('assets/park_speech.txt')
  wordnet = construct_wordnet(text)
  remove_low_frequency(wordnet)
  draw_graph(wordnet)
  plt.show()
#+END_SRC

#+RESULTS:
[[file:outputs/park_speech_nlp.png]]

#+BEGIN_SRC ipython :results raw :exports both :ipyfile outputs/park_speech_nlp_cutoff_3.png
  text = read_file('assets/park_speech.txt')
  wordnet = construct_wordnet(text)
  remove_low_frequency(wordnet, cutoff=3)
  draw_graph(wordnet)
  plt.show()
#+END_SRC

#+RESULTS:
[[file:outputs/park_speech_nlp_cutoff_3.png]]
